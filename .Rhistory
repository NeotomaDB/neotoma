install.packages("~/GitHub/neotoma.zip", repos = NULL)
install.packages("~/GitHub/neotoma.zip", repos = NULL)
library(neotoma)
install.packages("~/GitHub/neotoma_1.0.tar.gz", repos = NULL, type = "source")
library(sp)
library(spdep)
library(rgdal)
library(raster)
library(plyr)
#  Assumes you're in a working directory that contains the folder 'Maps':
ifelse(.Platform$OS.type=='unix',
setwd('/home/simon/Dropbox/WitnessTreeDensity'),
setwd('C:/Users/goring/Dropbox/WitnessTreeDensity'))
source('CleanFolder/misc.functionsv1.1.R')
#  Ramankutty raster, for use as a template.
pot.veg <- raster(read.asciigrid(fname='Maps/glpotveg_5min.asc'))
projection(pot.veg) <- '+proj=longlat +ellps=WGS84'
usa <- readOGR('Maps', 'us')
canada <- readOGR('Maps', 'PROVINCE')
#  This file was processed in the first file in this chain.
used.data <- readOGR('.', 'minn.wisc.mich.clean_v1_1')
data.box <- bbox(used.data)
data.box <- data.box + cbind(c(-1, -1), c(1, 1))
pot.veg <- crop(pot.veg, extent(data.box))
setwd("C:/Users/Simon Goring/Dropbox/WitnessTreeDensity/CleanFolder")
setwd('..')
getwd()
source('CleanFolder/misc.functionsv1.1.R')
pot.veg <- raster(read.asciigrid(fname='Maps/glpotveg_5min.asc'))
projection(pot.veg) <- '+proj=longlat +ellps=WGS84'
usa <- readOGR('Maps', 'us')
canada <- readOGR('Maps', 'PROVINCE')
#  This file was processed in the first file in this chain.
used.data <- readOGR('.', 'minn.wisc.mich.clean_v1_1')
colnames(used.data@data)
used.data@data$Township
grep('wi', x=used.data@data$Township)
length(grep('wi', x=used.data@data$Township))
dim(used.data)
head(grep('wi', x=used.data@data$Township))
?grep
regexpr('wi', x=used.data@data$Township)
regexpr('wi', used.data@data$Township)
sum(regexpr('wi', used.data@data$Township) > 0)
used.data <- used.data[regexpr('wi', used.data@data$Township) > 0,]
bbox(used.data)
data.box <- bbox(used.data)
data.box <- data.box + cbind(c(-1, -1), c(1, 1))
pot.veg <- crop(pot.veg, extent(data.box))
diams <- used.data@data[,4:7]
angles <- used.data@data[,16:19]
dists <- floor(used.data@data[,8:11])
species <- apply(used.data@data[,12:15], 2, as.character)
species[is.na(species)] <- 'NonTree'
sections <- c(2, 5, 8, 11, 14, 18, 21, 24, 27, 30,
34, 37, 40, 43, 46, 50, 53, 56, 59, 62,
66, 70, 74, 78, 82,
87, 89, 91, 93, 95, 98, 100, 102, 104, 106, 108,
109, 111, 113, 115, 117, 119, 122, 123, 124, 125, 126)
#  These are the points on the outside of each township.
external <- c(109:120, 97:108, 87, 89, 91, 93, 95, 122:126)
#  The corrections were written earlier, in the last
corrections <- read.csv('correctionv1.1.csv', stringsAsFactor=F)
sect <- used.data$Point %in% sections
extern <- used.data$Point %in% external
year <- as.character(used.data$year)
corr.vector <- cbind(sect, year, extern)
corr.index <- data.frame(first = rep(NA, nrow(used.data)),
secnd = rep(NA, nrow(used.data)))
#  There must be a better way, but I can't think of it.
#  I'm just trying to get a correction value for each point in the
#  large dataset:
cor.fun <- function(x){
value <- which(corr.vector[x,1] == corrections[,1] &
corr.vector[x,2] == corrections[,2] &
corr.vector[x,3] == corrections[,3])
if(!length(value) == 1) { out <- data.frame(first = NA, secnd = NA) }
else{ out <- data.frame(first = corrections[value,]$first,
secnd = corrections[value,]$Estimate)}
out
}
if('corr.index.csv' %in% list.files()){
corr.index <- read.csv('corr.index_v1.2.csv', row.names=1)
} else {
corr.index <- ldply(1:nrow(corr.vector), .fun=cor.fun, .progress = 'text')
write.csv(corr.index, 'corr.index_v1.2.csv')
}
##################################################################
#  morisita is a function found in misc.functions.r
estimates <- morisita(used.data, corr.index)
estimates.uncorr <- morisita(used.data)
stem.density <- estimates[[1]]
basal.area <- estimates[[2]]
stem.density <- SpatialPointsDataFrame(coordinates(used.data),
data=data.frame(density = estimates[[1]],
basal   = estimates[[2]],
diams = rowMeans(diams[,1:2], na.rm=TRUE) * 2.54))
proj4string(stem.density) <- proj4string(used.data)
#  Based on our knowledge of the dataset, assuming NA values are density 0 is
#  justified in some regions.
zero.trees <- is.na(stem.density$density) & (species[,2] %in% c('NonTree', 'Water') | species[,1] %in% c('NonTree', 'Water'))
stem.density$density[zero.trees] <- 0
stem.density$basal[zero.trees] <- 0
reproject <- function(x) projectRaster(x, crs='+init=epsg:3175')
pot.alb <- reproject(pot.veg)
bbox.new <- bbox(pot.alb)
ext.new <- extent(floor(bbox.new[1,1]/8000) * 8000,
ceiling(bbox.new[1,2]/8000) * 8000,
floor(bbox.new[2,1]/8000) * 8000,
ceiling(bbox.new[2,2]/8000) * 8000)
res.xy <- apply(bbox(ext.new), 1, diff) / 8000
base.rast <- raster(ext = ext.new, nrows = res.xy[2], ncols = res.xy[1],
crs = '+init=epsg:3175')
#  Once that's done, we rasterize, taking the mean value.
#  We're using the Albers projection at a grid resolution of
dens <-  rasterize(x = spTransform(stem.density,CRSobj=CRS('+init=epsg:3175')),
y=base.rast,
field = 'density',
fun=mean)
dens.sd <-  rasterize(x = spTransform(stem.density,CRSobj=CRS('+init=epsg:3175')),
y = pot.veg,
field = 'density',
fun=sd)
count.up <-  rasterize(x = spTransform(stem.density,CRSobj=CRS('+init=epsg:3175')),
y=base.rast,
field = 'density',
fun=function(x, ... ){sum(!is.na(x), na.rm=T)})
basal <- rasterize(x = spTransform(stem.density,CRSobj=CRS('+init=epsg:3175')),
y=base.rast,
field = 'basal',
fun=mean)
basal.sd <- rasterize(x = spTransform(stem.density,CRSobj=CRS('+init=epsg:3175')),
y=base.rast,
field = 'basal',
fun=sd)
mdiam <-  rasterize(x = spTransform(stem.density,CRSobj=CRS('+init=epsg:3175')),
y=base.rast,
field = 'diams',
fun=mean)
data.table <- data.frame(xyFromCell(dens, 1:ncell(dens)),
stem.density = getValues(dens),
basal.area = getValues(basal))
data.table <- data.table[!is.na(data.table[,3]), ]
write.csv(data.table, 'density.and.basal.area_v1_3wiscalb.csv')
data.table.repro <- data.frame(xyFromCell(reproject(dens), 1:ncell(reproject(dens))),
stem.density = getValues(reproject(dens)),
basal.area = getValues(reproject(basal)))
data.table.repro <- data.table.repro[!is.na(data.table.repro[,3]), ]
base.out <- setValues(base.rast, 1:ncell(base.rast))
point.cells <- extract(base.out,
spTransform(used.data, CRSobj=CRS(projection(base.rast))))
composition.coords <- xyFromCell(base.rast, 1:ncell(base.rast))
col.set <- unique(as.vector(species))
comp.fun <- function(x){
species.table <- table(as.vector(species[point.cells == x,1:2]))
output <- rep(NA, length(col.set))
names(output) <- col.set
if(!length(species.table) == 0){
output[match(names(species.table), as.character(col.set),nomatch=0)] <- species.table
}
output
}
composition.table <- ldply(1:ncell(base.rast), .fun=comp.fun, .progress='text')
projection(base.rast)
proj4string(used.data)
base.out <- setValues(base.rast, 1:ncell(base.rast))
point.cells <- extract(base.out,
spTransform(used.data, CRSobj=CRS(projection(base.rast))))
composition.coords <- xyFromCell(base.rast, 1:ncell(base.rast))
col.set <- unique(as.vector(species))
comp.fun <- function(x){
species.table <- table(as.vector(species[point.cells == x,1:2]))
output <- rep(NA, length(col.set))
names(output) <- col.set
if(!length(species.table) == 0){
output[match(names(species.table), as.character(col.set),nomatch=0)] <- species.table
}
output
}
composition.table <- ldply(1:ncell(base.rast), .fun=comp.fun, .progress='text')
#  Get rid of the NAs in the dataset, except for those where no cells have any data.
composition.table[is.na(composition.table)] <- 0
composition.table[rowSums(composition.table) == 0, ] <- NA
composition.table <- data.frame(composition.coords,
composition.table)
colnames(composition.table) <- c('x', 'y', as.character(col.set))
head(composition.table)
write.csv(composition.table, 'glo.forest.composition_v1_3wiscalb.csv')
colMeans(composition.table[,3:ncol(composition.table)]/rowSums(composition.table[,3:ncol(composition.table)], na.rm=TRUE), na.rm=TRUE
)
colSums(composition.table[,3:ncol(composition.table)]/rowSums(composition.table[,3:ncol(composition.table)], na.rm=TRUE) > 0.05, na.rm=TRUE)
sort(colSums(composition.table[,3:ncol(composition.table)]/rowSums(composition.table[,3:ncol(composition.table)], na.rm=TRUE) > 0.05, na.rm=TRUE))
sort(colSums(composition.table[,3:ncol(composition.table)]/rowSums(composition.table[,3:ncol(composition.table)], na.rm=TRUE) > 0.01, na.rm=TRUE))
sort(apply(composition.table[,3:ncol(composition.table)]/rowSums(composition.table[,3:ncol(composition.table)], na.rm=TRUE), 2, max, na.rm=TRUE))
sort(colSums(composition.table[,3:ncol(composition.table)]/rowSums(composition.table[,3:ncol(composition.table)], na.rm=TRUE) > 0, na.rm=TRUE))
comp.stack <- setValues(dens, composition.table[,3]/rowSums(composition.table[,3:32]))
for(i in 4:ncol(composition.table)){
comp.stack <- stack(comp.stack, setValues(dens, composition.table[,i]/rowSums(composition.table[,3:32])))
}
#  Now we have pointwise estimates for stem.density and basal area.
taxon.ba <- basal.area * ((diams[,1:2]^2)/rowSums(diams[,1:2]^2))
#  These are the biomass conversions for
biomass.betas <- data.frame(asp.ald.pop.wil = c(-2.2094, 2.3867),
smap.bi = c(-1.9123, 2.3651),
mix.hdwd = c(-2.4800, 2.4835),
hdmap.oak.hik.bee = c(-2.0127, 2.4342),
cd.lar = c(-2.0336, 2.2592),
fir.hem = c(-2.5384, 2.4814),
pine = c(-2.5356, 2.4349),
spr = c(-2.0773, 2.3323),
juniper = c(-0.7152, 1.7029),
nothing = c(0, 0))
in.set <- data.frame(sp = sort(as.character(unique(species[,1]))),
bm.code = c(10, 1, 3, 3, 4, 2, 5, 3,
3, 3, 3, 6, 3, 6, 4, 3,
9, 3, 10, 4, 7, 1, 3, 8,
3, 5, 3, 10, 1))
#  Now, to get the proper equation we need to match the species to the
#  data table:
bio.param <- data.frame(sp1 = in.set[match(species[,1], in.set[,1]),2],
sp2 = in.set[match(species[,2], in.set[,1]),2])
biomass <- matrix(nrow = nrow(bio.param), ncol = 2)
for(i in 1:nrow(biomass)){
if(species[i,1] == 'NonTree') x1 <- 0
else {
x1 <- exp(biomass.betas[1,bio.param[i,1]] + biomass.betas[2,bio.param[i,1]] * log(diams[i,1] * 2.54))
}
if(species[i,2] == 'NonTree'){
x2 <- 0
}
else{
x2 <- exp(biomass.betas[1,bio.param[i,2]] + biomass.betas[2,bio.param[i,2]] * log(diams[i,2] * 2.54))
}
biomass[i,] <- c(x1, x2)
if(i %% 300 == 0) cat(i, '\n')
}
biomass.ha <- biomass * stem.density$density
biomass.ha[is.nan(biomass.ha)] <- 0
stem.density@data$biomass <- rowMeans(biomass.ha, na.rm=TRUE)
#  This is cumulative biomass:
bio.ha <- rasterize(spTransform(stem.density,CRSobj=CRS('+init=epsg:3175')),
base.rast, field = 'biomass', fun=mean, na.rm=TRUE)
bio.sd <- rasterize(spTransform(stem.density,CRSobj=CRS('+init=epsg:3175')),
base.rast, field = 'biomass', fun=sd, na.rm=TRUE)
data.table <- data.frame(xyFromCell(dens, 1:ncell(dens)),
stem.density = getValues(dens),
basal.area = getValues(basal),
biomass = getValues(bio.ha),
stem.diam = getValues(mdiam))
head(data.table)
col.set <- unique(as.vector(species))
biom.fun <- function(x){
test.set <- biomass.ha
test.set[!species[,1:2] == x] <- 0
sp.biomass <- rowMeans(test.set, na.rm=TRUE)
runit <- SpatialPointsDataFrame(SpatialPoints(used.data,
proj4string=CRS(proj4string(used.data))),
data=data.frame(biom =sp.biomass))
run.alb <- spTransform(runit, CRSobj=CRS(projection(base.rast)))
sp.vals <- rasterize(run.alb,
base.rast,
field = 'biom',
fun = mean)
getValues(sp.vals)
}
biomass.table <- t(ldply(col.set, .fun=biom.fun, .progress='text'))
colnames(biomass.table) <- col.set
biomass.table <- data.frame(xyFromCell(base.rast, 1:ncell(base.rast)), biomass.table)
biomass.table[1,]
plot(x, y, biomass.table[!rowSums(is.na(biomass.table))>(ncol(biomass.table)-2),])
plot(x, y, data=biomass.table[!rowSums(is.na(biomass.table))>(ncol(biomass.table)-2),])
plot(biomass.table[!rowSums(is.na(biomass.table))>(ncol(biomass.table)-2),1:2])
plot(biomass.table[!rowSums(is.na(biomass.table))==(ncol(biomass.table)-2),1:2])
write.csv(biomass.table, 'biomassbysp_1_3_albwisc.csv')
etwd()
getwd()
library(vegan)
library(MASS)
aa <- matrix(runif(1000, 0, 2), ncol=10)
colnames(aa) <- 1:10
bb <- metaMDS(aa)
biplot(bb)
plot(bb)
?metaMDS
plot(bb, type='t')
bb$points
bb$species
library(neotoma)
get.sites
get.sites()
get_sites
